{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOV5pBG3HwRCRlBLnWCmAqN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GoZaZombie/CTIP-Assignment-2/blob/main/NaiveBayesTrain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHtKnKpFdeCK",
        "outputId": "bc61b5f1-61b3-49d0-e5e7-9f24b73a2522"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Confusion Matrix:\n",
            "[[1675  156]\n",
            " [   5  424]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.91      0.95      1831\n",
            "           1       0.73      0.99      0.84       429\n",
            "\n",
            "    accuracy                           0.93      2260\n",
            "   macro avg       0.86      0.95      0.90      2260\n",
            "weighted avg       0.95      0.93      0.93      2260\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "#import datasets\n",
        "#debug\n",
        "SpamData1 = pd.read_csv('emails.csv', encoding='latin-1')\n",
        "#print(SpamData1.tail(20))\n",
        "\n",
        "SpamData2 = pd.read_csv('spam.csv', encoding='latin-1')\n",
        "#debug\n",
        "#print(SpamData2.tail(20))\n",
        "\n",
        "#Normalizing the column name scheme\n",
        "SpamData2 = SpamData2.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1)\n",
        "SpamData2 = SpamData2.rename(columns={'v1': 'Classification', 'v2': 'Message'})\n",
        "SpamData1 = SpamData1.rename(columns={'text': 'Message','spam': 'Classification'})\n",
        "#reorder Columns\n",
        "SpamData1 = SpamData1[['Message', 'Classification']]\n",
        "SpamData2 = SpamData2[['Message', 'Classification']]\n",
        "#normalize values for spam and \"ham\"\n",
        "SpamData2.loc[SpamData2['Classification'] == 'spam', 'Classification'] = 1\n",
        "SpamData2.loc[SpamData2['Classification'] == 'ham', 'Classification'] = 0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#debugging\n",
        "##print(SpamData1.tail(20))\n",
        "#print(SpamData2.tail(20))\n",
        "\n",
        "#join the data sets\n",
        "SpamData = pd.concat([SpamData1, SpamData2], ignore_index=True)\n",
        "\n",
        "#debugging\n",
        "#print(SpamData.tail(20))\n",
        "\n",
        "\n",
        "# prepare data for Naive Bayes\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(SpamData['Message'])\n",
        "Y = SpamData['Classification'].astype(int) #seperates the data into x and y. x being the messages and y being the classification.\n",
        "\n",
        "X_TrainData, X_TestData, Y_TrainData, Y_TestData = train_test_split(X, Y , test_size=0.2, random_state =42) #splits the data into training and testing sets, currently 80 - 20 split\n",
        "\n",
        "\n",
        "# Initialize and train Naive Bayes model\n",
        "naive_bayes_model = MultinomialNB()\n",
        "naive_bayes_model.fit(X_TrainData, Y_TrainData)\n",
        "\n",
        "\n",
        "# Evaluate the model\n",
        "Y_PredData = naive_bayes_model.predict(X_TestData)\n",
        "\n",
        "print(\"\\nConfusion Matrix:\") #TP FP FN TN\n",
        "print(confusion_matrix(Y_TestData, Y_PredData))\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(Y_TestData, Y_PredData))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_Vd4AmcogvBf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}